<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0051)http://www.eia.gov/consumption/commercial/data/archive/cbecs/howconducted.html -->
<HTML><HEAD><TITLE>How the 2003 CBECS Was Conducted</TITLE>
<META http-equiv=Content-Type content="text/html; charset=iso-8859-1">
<META content="Joelle Davis" name=Author>
<META content="MSHTML 6.00.2900.2523" name=GENERATOR>
<META 
content="commercial, commercial buildings, 1999 CBECS, questionnaire design, data collection" 
name=KeyWords>
<META 
content="Information about what constitues a commercial building for the CBECS, how the questionnaire was designed, interviewer training, and how the data were collected" 
name=Description>
<link rel="stylesheet" href="https://www.eia.gov/styles/eia_sitewideF.css" type="text/css">
<script language="JavaScript" src="https://www.eia.gov/styles/eia_header.js" type="text/javascript"></script>
<script language="JavaScript" src="https://www.eia.gov/styles/eia_footer.js" type="text/javascript"></script>
<style type="text/css">
<!--
.style2 {color: #D4D0C8}
-->
</style>
</HEAD>
<body leftMargin="0" topMargin="0" marginwidth="0" marginheight="0">
<!-- ****************************************** Begin HEADER ************************************************ -->
<!-- BEGIN BANNER, & SEARCH -->
<script language="JavaScript">InsertEIAHeaderCode();</script> 

<!-- END OF SEARCH & BANNER -->
    <!-- ****************************************** End HEADER ************************************************** -->

    <!-- THIS BEGIN THE MAIN CONTENT TABLE-->
    <!-- INSERT CONTENT HERE-->
<td height="8" valign="TOP"><span class="breadcrumbs"><a href="../../../../../index.html">Home</a> 
          > <a href="description_files/plainlink.css.html">Households, 
            Buildings &amp; Industry</a> &gt;</span>  </span><span class="breadcrumbs"><a href="https://www.eia.gov/consumption/commercial/">Commercial Buildings Energy Consumption Survey (CBECS)</a> </span> <span class="breadcrumbs">&gt;</span> <span class="breadcrumb"> <span class="breadcrumbs"><a href="https://www.eia.gov/consumption/commercial/data/archive/cbecs/technical_information.html">Technical Information</a> </span> <span class="breadcrumbs">&gt;</span> </span><span class="breadcrumbshd">Sample Design </span></td></tr>
			<td valign="TOP"> 
			<p>&nbsp;
<TABLE cellSpacing=0 cellPadding=4 width=95%% bgColor=#ffffff>
  <TBODY>
    <TR align=left> 
      <TD width=85% vAlign=top>         <P align="center" class="SubSection"><span class="Pagetitle">2003 
            Commercial Buildings <br>
            Energy Consumption Survey: <br>
            How the Survey Was Conducted</span> 
          </span><br>        
        <P align="left" class="CategoryTitle">
      Introduction
            
      <P align=justify><span class="SubSection">The 
          Commercial Buildings Energy Consumption Survey (CBECS) is conducted 
          quadrennially by the Energy Information Administration (EIA) to provide 
          basic statistical information about energy consumption and expenditures 
          in U.S. commercial buildings and information about energy-related characteristics 
          of these buildings. The survey is based upon a sample of commercial 
          buildings selected according to the sample design requirements described 
          below. A “building,” as opposed to an “establishment,” is the basic 
          unit of analysis for the CBECS because the building is the energy-consuming 
          unit.&nbsp; The 2003 CBECS was the eighth survey  conducted 
          since 1979 </span>
      <P align=justify class="SubSection">The 
          CBECS is conducted in two data-collection stages: a Building Characteristics 
          Survey and an Energy Suppliers Survey.&nbsp; The Energy Suppliers Survey 
          is initiated only if the respondents to the Building Characteristics 
          Survey can not provide the energy consumption and expenditures information, 
          or the information provided fails edits within the survey instrument. 
          The Building Characteristics Survey collects information about selected 
          commercial buildings through voluntary interviews with the buildings’ 
          owners, managers, or tenants.&nbsp; In the 2003 survey, these data were 
          collected using Computer-Assisted Personal Interviewing (CAPI) techniques.</P>
        <P align=justify class="SubSection">During 
          the Building Characteristics Survey, respondents are asked questions 
          about the building size, how the building is used, types of energy-using 
          equipment and conservation measures that are present in the building, 
          the types of energy sources used, and the amount and cost of energy 
          used in the building.</P>
        <P align=justify class="SubSection">Upon 
          completion of the Building Characteristics Survey, the Energy Suppliers 
          Survey is initiated for those cases that did not provide satisfactory 
          consumption and expenditures information. This Suppliers Survey obtains 
          data about the building’s actual consumption of and expenditures for 
          energy from records maintained by energy suppliers.&nbsp; These billing 
          data are collected in a mail survey conducted under EIA’s mandatory 
          data collection authority. A survey research firm, under contract to 
          EIA, conducts both the interviews for the Building Characteristics Survey 
          and the mail survey for the Energy Suppliers Survey.</P>
        <P align=justify class="CategoryTitle">2003 
          CBECS 
        <P class="SubSection">This document 
          describes the 2003 CBECS sample design, including the target population, 
          the sample frames and sample selection rates, response rates, and the 
          adjustment for unit nonresponse.&nbsp; Other information about survey 
          procedures and methodology can be found in <A 
      href="https://www.eia.gov/consumption/commercial/data/archive/cbecs/technical_information.html">"Technical 
          Information on CBECS"</A> and <A 
      href="https://www.eia.gov/consumption/commercial/data/archive/cbecs/background.html">"Background Information 
          on CBECS"</A>.</P>
       <TABLE width="85%" bgColor=#ffffe6 border=1>
          <TBODY>
            <TR> 
              <TD> <div align="center"><span class="CategoryTitle">Highlights 
                    of Changes in the 2003 CBECS 
                    </CENTER>
                  </span>
                </div>
                <UL>
                  <LI><SPAN class="SubSection">First 
                    CBECS since 1986 to be collected under a new sample design</SPAN></LI>
                </UL>
                <UL>
                  <LI><SPAN class="SubSection">Return 
                    to Computer Assisted Personal Interviewing (CAPI) after using 
                    telephone interviewing in 1999&nbsp; </span></LI>
                </UL>
                <UL>
                  <LI><span class="SubSection">New 
                    procedures for sampling and interviewing at shopping malls</span></LI>
                </UL>
                <UL>
                  <LI><span class="SubSection">Requested 
                    sample electricity and/or natural gas bills from respondents 
                    to assist in data editing</span></LI>
                </UL>
                <UL>
                  <LI><span class="SubSection">Data 
                    edited in-house by CBECS program staff</span></LI>
                </UL>
                <UL>
                  <LI><SPAN class="SubSection">Questionnaire 
                    expanded with new questions on topics such as building structure 
                    and specialized equipment</span></LI></UL></TD></TR></TBODY></TABLE>
        <br>
          <span class="CategoryTitle">Determining Building Eligibility </span>        <P align="justify" class="SubSection">A 
          building is eligible for the CBECS if it meets three criteria: building 
          definition, building use, and building size.&nbsp; Determining this 
          eligibility is a two-step process.&nbsp; In 2003, the first step occurred 
          during the development of the sample and the second step occurred during 
          the interview with the building respondent.&nbsp; 
        <P align="justify"><span class="SubSection"><I>Criterion 
          1—Building Definition:</I>&nbsp; The definition of a building was the 
          same one used in the past: a structure totally enclosed by walls that 
          extend from the foundation to the roof that is intended for human access. 
          Therefore, structures such as water, radio, and television towers were 
          excluded from the survey.&nbsp; Also excluded were: partially open structures, 
          such as lumber yards; enclosed structures that people usually do not 
          enter or are not buildings, such as pumping stations, cooling towers, 
          oil tanks, statues, or monuments; dilapidated or incomplete buildings 
          missing a roof or a wall; and, beginning with the 1995 CBECS, stand-alone 
          parking garages. There is one exception to the building definition criterion—structures 
          built on pillars so that the first fully enclosed level is elevated 
          are included. These types of buildings are included because such buildings 
          fall short of meeting the definition due only to the technical shortcoming 
          of being raised from the foundation. They are totally enclosed, are 
          used for common commercial purposes, and use energy in much the same 
          way as buildings that sit directly on a foundation. </span>
        <P align="justify"><span class="SubSection"><I>Criterion 
          2—Building Use:</I>&nbsp; In order to be included in the 
          CBECS, a building had to be used primarily for some commercial purpose; 
          that is, more than 50 percent of the building’s floorspace must have 
          been devoted to activities that were neither residential, industrial, 
          nor agricultural. The primary use of the sampled building governed whether 
          the building was included in the CBECS.&nbsp; Beginning with the 1995 
          CBECS, there was one exception to this criterion: commercial buildings 
          on manufacturing sites were considered out of scope. (In previous CBECS, 
          if a commercial building, such as an office building, was located on 
          a manufacturing site, it would have been considered in scope.)&nbsp; </span>        <P align="justify"><span class="SubSection">Examples 
          of nonresidential buildings that were <I>not</I> included in the CBECS 
          sample are:&nbsp; 
          </span>
          <div align="justify"> 
          <UL>
            <LI class="SubSection">farm 
              buildings, such as barns, (unless space is used for retail sales 
              to the general public)</LI>
          </UL>
          <UL>
            <LI class="SubSection">industrial 
              or manufacturing buildings that involve the processing or procurement 
              of&nbsp; goods, merchandise, or food (again, unless space is used 
              for retail sales to the general public)</LI>
          </UL>
          <UL>
            <LI class="SubSection">buildings 
              on most military bases; buildings where access is restricted for 
              national security reasons</LI>
          </UL>
          <UL>
            <LI><span class="SubSection">single-family 
              detached dwellings that are primarily residential, even if the occupants 
              use part of the dwelling for business purposes; and&nbsp; </span></span></LI>
          </UL>
          <UL>
            <LI class="SubSection">mobile 
              homes that are not placed on a permanent foundation (even if the 
              mobile home is used for nonresidential purposes). </LI>
          </UL>
          <p class="SubSection"><I>Criterion 
            3—Building Size:&nbsp;</I> A commercial building had to measure 
            more than 1,000 square feet (about twice the size of a two-car garage) 
            to be considered in scope for the 2003 CBECS.&nbsp; This building size 
            criterion was met in two successive size cutoffs, which were enacted 
            during the sample development and interviewing stages.&nbsp; During 
            the development stage, buildings judged to be less than 500 square feet 
            were not enumerated.&nbsp; Then during the interviewing stage, interviewers 
            asked screening questions designed to terminate the interview when the 
            square footage was reported to be 1,000 square feet or less (except for interviews at establishments within malls, for which there was no minimum square footage). </p>
          <p class="CategoryTitle">Data 
          Collection        </p>
          </div>
        <P align="justify" class="SubSection">Data 
          collection encompasses several phases, including: (1) designing the 
          questionnaire, (2)&nbsp; pretesting the questionnaire, (3) training 
          supervisors and interviewers, (4) conducting interviews, (5) minimizing 
          nonresponse, and (6) processing the data. 
        <em>Questionnaire 
          Design</em> 
        <P align="justify"><span class="SubSection">Although 
          a set of core questions remained the same or very similar to those used 
          in previous surveys, the 2003 Building Questionnaire was expanded somewhat 
          compared to the 1999 survey. Certain questions that had been absent 
          for a couple survey cycles were brought back for 2003 (such as wall 
          and roof construction materials and building shape), and some completely 
          new questions were added, mainly dealing with specialized equipment 
          used in the building. 
        </span>
        <P align="justify"><span class="SubSection">The 
          survey instrument also had to be redesigned to accomodate the interviews 
          at establishments within malls. These interviews varied somewhat from 
          building interviews, mainly in the wording of questions.
        </span>
        <P align="justify"><span class="SubSection">The 
          CAPI survey instrument was programmed by EIA using Blaise software. 
          
            <em>Pretest</em> 
        </span>
        <P align="justify"><span class="SubSection">One 
          pretest was conducted prior to fielding the full-scale survey to determine 
          if the programmed questionnaire worked as intended and to test the new 
          procedures for interviewing in establishments. Interviewers administered 
          71 questionnaires with buildings and establishments of different primary 
          activities and sizes.
            <em>Supervisor 
          and Interviewer Training</em> 
        </span>
        <P align="justify"><span class="SubSection">The 
          CBECS building questionnaire is a complex instrument designed to collect 
          data during a personal interview with a respondent at the building site. 
          Well-trained interviewers are imperative to the collection of technical 
          information. Training for the 2003 CBECS included three in-person six-day 
          training sessions: one session for the CBECS home office, trainers, 
          and regional supervisors and two separate sessions for two different 
          groups of interviewers.&nbsp; All prospective interviewers received 
          a home study package before reporting to training, including a CBECS 
          introductory video. A home study exercise was required to be turned 
          in to be graded at training registration. New interviewers received 
          general interviewer training on the first day of training. Training 
          sessions included lectures, videos, interactive interviews, slide presentations, 
          and sessions where the interviewers practiced administering the questionnaire 
          to each other using scripts provided to them. There was at least one 
          EIA representative in each training group playing an active role in 
          the instruction&#8212;presenting some of the training sessions and providing 
          assistance where needed. <em>Conducting 
          the Interviews</em> 
        </span>
        <P align="justify"><span class="SubSection">CBECS 
          interviews began near the beginning of August 2003, and closed at the 
          end of January 2004. Data collection was performed by the contractor's 
          field staff which consisted of 208 interviewers across the U.S. under 
          the supervision of 13 regional supervisors, 3 field managers, an office-based 
          assistant field director and a field director.&nbsp; Each building in 
          the sample began with a screener and then proceeded with the extended 
          interview.&nbsp; 
        </span>
        <P align="justify"><span class="SubSection"><I>Screener:</I> 
          Interviewers visited the sampled building in person to locate the building, 
          determine if the structure met the eligibility criteria and to determine 
          the boundaries of the building that was the subject of the interview. 
          This was necessary because there were instances where what had been 
          assigned to the interviewer as a single building was, in fact, more 
          than one building, where the boundaries extended beyond what the sample 
        frame had described, or where the building could not be located.         
        </span>
        <P align="justify"><span class="SubSection">Also during 
            this screening visit, interviewers listed the establishments in buildings 
            that turned out to be shopping centers or malls. This list was subsequently 
            sent to the contractor&#8217;s home office, where it was keyed, sampled, 
            and selected establishments returned to the field for interview. </span>
        <p align="justify" class="SubSection">Also 
          during this initial contact with either the building or an establishment, 
          interviewers located a knowledgeable respondent for the interview, left 
          an advance package of materials with or for that person, and made an 
          appointment to return for an interview after allowing enough time for 
          the respondent to look over and fill out the survey materials. </p>
        <P align="justify"><span class="SubSection"><I>Advance 
          Package: </I>An introductory packet of materials was given to the respondent 
          or the respondent&#8217;s representative before the interview. It contained 
          letters on DOE and contractor letterhead explaining the study and the 
          type of information requested, an information card summarizing key findings 
          of the 1999 study, a CBECS brochure explaining the importance of the 
          study, and two worksheets that were to be completed by the respondent 
          before the interview. </span>          <P align="justify"><span class="SubSection"><I>Extended 
          Interview: </I>After allowing time for the respondent to look over the survey materials and complete the worksheets, the 
          inteviewer returned to the building or establishment at their set appointment time to conduct the 
          CBECS interview. The questionnaire covered topics such as: physical 
          characteristics such as building activity, size and year constructed; 
          building use patterns such as operating hours, number of workers, ownership 
          and occupancy questions; types of energy-using equipment such as heating, 
          cooling, refrigeration, lighting and office equipment; conservation 
          features and energy management practices; types of energy used in the 
          building and whether that energy is used for heating, cooling, water 
          heating, cooking, manufacturing or electricity generation; and the amount 
          of and expenditures for energy used in the building in 2003. (See <a href="file:///C|/Documents%20and%20Settings/LPJ/EMEU/cbecs/forms.html">Data 
          Collection Forms</a> for a paper representation of the survey instrument.)
          </span>
          <P align="justify"><span class="SubSection">The 
          average time to complete an interview was 30 minutes, with building 
          interviews taking about 31 minutes and establishment interviews taking 
          about 20 minutes.&nbsp; The average time to obtain each completed interview, 
          including interviewer preparation, travel time, screener time, interview 
          time, callbacks, and transmission to the home office, was a little over 
          11.5 hours.&nbsp; 
          </span>
          <P align="justify"><span class="SubSection"><I>Interviewer 
          Supervision: </I>The main procedure used to ensure that the interviews 
          were conducted as intended was validation, which is the process of verifying 
          that the interview had been conducted and that it had been conducted 
          at the correct building according to specified procedures. Ten percent 
          of the entire sample was preselected for validation. Validation took 
          place for completes as well as for ineligibles. Most were done from 
          the contractor&#8217;s telephone center where interviewers called the 
          respondent to determine if the interview took place and at what building 
          to make sure the interviewer followed CBECS procedures, was polite and 
          business-like, and to re-ask some questions from the interview. A few 
          validations were completed in person by the second interviewer in a 
          PSU or by a traveling interviewer. This was necessary for out-of-scope 
          Screener cases when no telephone was reported or there were suspicions 
          about the veracity of the interviewer&#8217;s work. </span>
          <p align="justify" class="SubSection">Discrepancies 
          recorded by the telephone interviewer that were not reconciled based 
          on very narrow criteria were given to the field director to review. 
          Based on the field director&#8217;s review, the case was either determined 
          to pass validation or required further action, in which case it was 
          referred to the supervisor to follow up with the interviewer. Whenever 
          a suspicious case was identified, all of that interviewer&#8217;s work 
        was validated.</p>
        <p align="justify"><em>Minimizing 
          Nonresponse</em> </p>
        <P align="justify">Field 
          work was completed within a PSU in overlapping phases: the initial assignment, 
          local reassignment (where possible), and reassignment to traveling interviewers. 
          The purpose of this plan was to have the flexibility to have a different 
          interviewer conduct refusal conversion or, if necessary, to remove work 
          from poorly performing interviewers. This plan was designed to achieve 
          the highest possible response rate.
        <P align="justify">Each week supervisors reviewed with each of their interviewers 
          all of their pending cases to monitor progress toward completion. Supervisors 
          probed to determine if cases were being worked systematically and calls 
          made judiciously. Reasons for refusals were discussed along with the 
          timing and placement of past and future contacts. Every effort was made 
          to ensure a successful outcome. Letters were sent by supervisors, the 
          field director, the project director, and occasionally by staff from 
          EIA, as appropriate, to encourage participation and to answer questions. 
          Telephone calls were made to, and received from, respondents to the 
          field director in the contractor&#8217;s home office and to staff at 
        EIA.        
        <p align="justify">Even with these efforts, confirmed nonresponse cases totaled 1,438 
          at the end of data collection. They were divided into two categories: 
          (1) refusals and (2) cases where an interview could not be obtained for some other reason, such as respondents 
          with whom there was trouble communicating because of a language barrier, those 
          who were unable to be contacted because they were generally not available, 
          and those who could not be confirmed for other miscellaneous reasons. </p>
        <p align="justify">The largest category of nonresponse resulted from refusals. When a 
          refusal was obtained, it was reviewed to determine if it should be subject 
          to a conversion attempt or finalized as a refusal. Firm refusals received 
          from the corporate level within an organization or refusals from respondents 
          who were hostile toward either the interviewer or the survey were not 
          recontacted. Among the initial refusals, about 11 percent were classified as firm refusals. Additionally, about another 9 percent of cases that were either isolated or were located in PSUs without an 
          appropriate interviewer to conduct conversion, the cost of attempting 
          conversion would have been extremely high. All of the remaining  
        refusals were considered candidates for refusal conversion.</p>
        <p align="justify">Before attempting in-person conversion, personalized letters were sent 
          to refusing respondents. Four types of letters were created that targeted 
          specific types of refusals: one general refusal conversion letter, one for respondents who claimed they did not have 
          time for the interview, one for respondents 
          who were not available during the first contact time period, and one for respondents who stated anti-Government 
          reasons for not participating. Once sufficient time had passed after 
          the letter was mailed, interviewers attempted to recontact the respondent 
          and obtain consent for an interview.</p>
        <p align="justify" class="style11">Of the  initial refusals subject to conversion, about 25 percent were converted to completes.
        </p>
        <P class="style13">Processing 
          the Data 
        <P align="justify">The 
          initial processing of the CBECS data, which included editing the questionnaires 
          and calculating the survey weights for each building, occurred at both 
          EIA and the survey contractor’s home office. Final data preparation 
          occurred at EIA and consisted of checking the data for internal consistency, 
          checking the data against data from previous surveys, conducting imputation 
          procedures for missing data, and preparing cross-tabulations for release 
          to the public.&nbsp; Additionally, for those buildings that could not 
          provide the energy consumption and expenditures data, authorization 
          forms were requested that permitted the survey contractor to contact 
          the energy supplier for that information.&nbsp; Upon receipt of the 
          authorization form, the information was entered into the CATI questionnaire.&nbsp; 
          
        <P align="justify"><I>Data 
          Editing:</I> While data editing for the 2003 CBECS Building Characteristics 
          Survey occurred at several points during data collection and processing, 
          the primary editing occurred during the CAPI interview.&nbsp; CAPI controlled 
          for skip pattern errors and the entry of ineligible codes.&nbsp; It 
          also permitted some editing of the data as the interview proceeded.&nbsp; 
          Arithmetic checks were conducted for some items, consistency checks 
          between items prompted interviewers to confirm unlikely responses, and 
          internal regression programs allowed for on-line editing of the energy 
          consumption and expenditures.&nbsp; Most edits were “soft” meaning that 
          they could be suppressed after the interviewer verified the information 
          with the respondent, but for a few crucial questions or “impossible” 
          data combinations, the interview could not continue until the edit was 
        resolved.        
        <P align="justify">Additional editing was performed
            at EIA upon completion of the CAPI interview; cases were transmitted from the contractor to EIA on a weekly basis for review. This editing included reviewing edits suppressed within the instrument, running additional edit checks that were considered to be important, but not crucial enough to stop the interview, updating data based on clarifying 
            comments that were provided by the interviewers, incorporating responses 
            to open-ended questions, and reviewing Don't Knows for certain &quot;critical items.&quot; In some of these cases, it was determined that a callback was worthwhile, and the contractor was notified to send that case back for data retrieval. 
        Data 
          Adjustments 
        <P align="justify"><I>Item 
          Nonresponse:</I> Prior to publication of the 2003 CBECS, adjustments 
          were made for item nonresponse.&nbsp; Item nonresponse is a specific 
          piece of information that is missing in an otherwise completed interview.&nbsp; 
          In the case of building interviews, the usual cause for item nonresponse 
          was that the building representative lacked the knowledge to answer 
          a questionnaire item.&nbsp; 
        <P align="justify">Item 
          nonresponses were treated by a technique known as “hot-deck imputation.”&nbsp; 
          In hot-decking, when a certain response is missing for a given building, 
          another similar building (a donor building) is randomly chosen to furnish 
          its reported value for that missing item.&nbsp; That value is then assigned 
          to the building (a receiver building) with the item nonresponse.&nbsp; 
          This procedure was used to reduce the bias caused by different nonresponse 
          rates for a particular item among different types of buildings.&nbsp; 
          
        <P align="justify">Donor 
          buildings had to be similar to the nonrespondent in characteristics 
          correlated with the missing item.&nbsp; The characteristics that were 
          used to define similar depended on the nature of the item to be imputed. 
          The most frequently used characteristics were principal building activity, 
          floorspace category, year constructed category and Census region.&nbsp; 
          Other characteristics (such as type of heating fuel and type of heating 
          and cooling equipment) were used for specific items.&nbsp; To hot-deck 
          values for a particular item, all buildings were first grouped according 
          to the values of the matching characteristics specified for that item.&nbsp; 
          Within each group defined by the matching variables, donor buildings 
          were assigned randomly to receiver buildings. 
        <P align="justify">As 
          was done in previous surveys, the 2003 CBECS used a vector hot-deck 
          procedure.&nbsp; With this procedure, the building that donated a particular 
          item to a receiver also donated certain related items if any of these 
          were missing.&nbsp; Thus, a vector of values, rather than a single value, 
          is copied from the donor to the receiver.&nbsp; This procedure helps 
          to keep the hot-decked values internally consistent, avoiding the generation 
        of implausible combinations of building characteristics.        
        <P align="justify" class="style4">Confidentiality 
              of Information </P>
        <P align="justify" class="style11">The names or addresses of individual respondents or any other individually identifiable&nbsp;data that could be specifically linked to an individual sample building or building respondent are seen only by&nbsp;employees of EIA,&nbsp;its&nbsp;survey contractor, and EIA-approved agents.&nbsp; The data are kept secure&nbsp;and confidential&nbsp;at all times. The 2003 CBECS is the first&nbsp;survey cycle&nbsp;for which EIA took possession of&nbsp;specific building identifiers.&nbsp; This&nbsp;change, which&nbsp;gives EIA greater capability to handle and manage its data,&nbsp;was the result of a new Federal law, the Confidential Information Protection and Statistical Efficiency Act of 2002 (CIPSEA).&nbsp; The&nbsp;legislation gives EIA both the authority and the responsibility&nbsp;to protect&nbsp;from disclosure&nbsp;identifiable data&nbsp;which respondents have been promised would be kept confidential and used&nbsp;exclusively&nbsp;for statistical purposes.&nbsp; The CBECS meets these criteria, and the 2003 cycle was collected under CIPSEA protection.</P>
        <div align="justify">In order to meet our responsibilities for protecting data for individual respondents,&nbsp;all building identifiers are removed from the data file before the public use microdata file is created. The finest level of geographic detail that is&nbsp;publicly available&nbsp;is the Census division. In addition, building characteristics that could potentially identify a particular responding building, such as number of floors, building square footage, and number of workers in the building, are masked to protect the respondent's identity.
          </P>        
          </span>        
        </div>
        <P align="justify"><a href="2003howconducted.html#top">Top</a>
        
        
        <P> 
        <HR width="85%" SIZE=1> <BR> 
        Contacts</span>
        <DL>
          <DT>Specific questions 
            on this product may be directed to:<br>
            <br>
             
          <DD>Joelle Michaels 
             
          <DD><A 
        href="mailto:joelle.michaels@eia.doe.gov">joelle.michaels@eia.doe.gov</A> 
             
          <DD>CBECS Manager 
             
          <DD></TR>
  </TBODY></table></DIV></CENTER>
URL: http://www.eia.gov/consumption/commercial/data/archive/cbecs/2003howconducted.html
<!-- START FOOTER HERE -->
<script language="JavaScript">InsertEIAFooterCode();</script> 
</body>
</html>